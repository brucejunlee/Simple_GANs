{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Nets (GANs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative models\n",
    "\n",
    "It is different from discriminative models, where samples are usually drawn from conditional distributions. Moreover, in the generative modeling, we don't need labels.\n",
    "\n",
    "Generative models include AutoEncoders and GANs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts\n",
    "\n",
    "Two-player game, that is a minimax optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two ways of research\n",
    "\n",
    "+ Stablize the training: Vanilla GAN, Conditional GAN, Coupled GAN, ALI, DCGAN, InfoGAN, f-GAN, LSGAN, Energy-based GAN, Boundary_Equilibrium GAN, PacGAN, Triple-GAN, SN-GAN, Wasserstein GAN, WGAN-GP, MMD-GAN\n",
    "\n",
    "+ applications in interesting areas: StackGAN, CycleGAN, LAPGAN, Progressive Growing GAN, Pix2Pix, SRGAN, Self-Attention GAN, BigGAN, BiGAN, BigBiGAN, SeqGAN, EEG-GAN, Social GAN, DVD-GAN\n",
    "\n",
    "**Generative adversarial networks (GANs) have been at the forefront of research on generative models in the last couple of years. GANs have been used for image generation, image processing, image synthesis from captions, image editing, visual domain adaptation, data generation for visual recognition, and many other applications, often leading to state of the art results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incomplete References\n",
    "\n",
    "D. Barber and F. Agakov, The IM Algorithm : A variational approach to Information Maximization, NIPS 2003.\n",
    "\n",
    "I. Goodfellow, et al., Generative Adversarial Nets, NIPS 2014. (**Vanilla GAN**)\n",
    "\n",
    "M. Mirza and S. Osindero, Conditional Generative Adversarial Nets, Computer Science, 2014. (**CGAN**)\n",
    "\n",
    "J. Gauthier, Conditional generative adversarial nets for convolutional face generation, 2015.\n",
    "\n",
    "E. Denton, et al., Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks, NIPS 2015. (**LAPGAN**)\n",
    "\n",
    "C. Dong, et al., Image super-resolution using deep convolution networks, IEEE TPAMI, 2015.\n",
    "\n",
    "T. Salimans, et al., Improved Techniques for Training GANs, NIPS 2016.\n",
    "\n",
    "A. Radford, et al., Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks, ICLR 2016. (**DCGAN**)\n",
    "\n",
    "S. Nowozin, B. Cseke, and R. Tomioka, f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization, NIPS 2016. (**f-GAN**)\n",
    "\n",
    "Ming-Yu Liu and Oncel Tuzel, Coupled generative adversarial networks, NIPS 2016. (**CoGAN**)\n",
    "\n",
    "X. Chen, et al., InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets, NIPS 2016. (**InfoGAN**)\n",
    "\n",
    "S. Reed, et al., Generative Adversarial Text to Image Synthesis, ICML 2016.\n",
    "\n",
    "C. Ledig, et al., Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network, CVPR 2016.\n",
    "\n",
    "J. Wu, et al., Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling, NIPS 2016. (**3D-GAN**)\n",
    "\n",
    "P. Isola, J.-Y. Zhu, T. Zhou and A. A. Efros, Image-to-Image Translation with Conditional Adversarial Networks, CVPR 2017. (**Pix2Pix**)\n",
    "\n",
    "X. Mao, et al., Least Squares Generative Adversarial Networks, ICCV 2017. (**LSGAN**)\n",
    "\n",
    "V. Dumoulin, et al., Adversarially Learned Inference, ICLR 2017. (**ALI**)\n",
    "\n",
    "J. Donahue, et al., Adversarial Feature Learning, ICLR 2017. (**BiGAN**)\n",
    "\n",
    "J. Zhao, M. Mathieu and Y. LeCun, Energy-based Generative Adversarial Networks, ICLR 2017. (**EBGAN**)\n",
    "\n",
    "D. Berthelot, et al., BEGAN: Boundary Equilibrium Generative Adversarial Networks, 2017. (**BEGAN**)\n",
    "\n",
    "L. Metz, et al., Unrolled Generative Adversarial Networks, ICLR 2017.\n",
    "\n",
    "C. Li, et al., Triple Generative Adversarial Nets, NIPS 2017. (**Triple-GAN**)\n",
    "\n",
    "M. Arjovsky and L. Bottou, Towards Principled Methods for Training Generative Adversarial Networks, ICLR 2017.\n",
    "\n",
    "M. Arjovsky, S. Chintala and L. Bottou, Wasserstein Generative Adversarial Networks, ICML 2017. (**WGAN**)\n",
    "\n",
    "H. Zhang, et al., StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks, ICCV 2017. (**StackGAN**)\n",
    "\n",
    "J.-Y. Zhu, et al., Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks, ICCV 2017. (**CycleGAN**)\n",
    "\n",
    "C. Ledig, et al., Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network, CVPR 2017. (**SRGAN**)\n",
    "\n",
    "L. Yu, et al., SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient, AAAI 2017. (**SeqGAN**)\n",
    "\n",
    "H. Petzka et al., On the Regularization of Wasserstein GANs, ICLR 2018.\n",
    "\n",
    "I. Gulrajani, et al., Improved Training of Wasserstein GANs, NIPS 2018. (**WGAN-GP**)\n",
    "\n",
    "T. Miyato, et al., Spectral Normalization for Generative Adversarial Networks, ICLR 2018. (**SN-GAN**)\n",
    "\n",
    "Z. Lin, et al., PacGAN: The power of two samples in generative adversarial networks, NIPS 2018. (**PacGAN**)\n",
    "\n",
    "T. Karras, et al., Progressive Growing of GANs for Improved Quality, Stability, and Variation, ICLR 2018. (**PGAN**)\n",
    "\n",
    "C. Li, et al., Graphical Generative Adversarial Networks, NIPS 2018. (**Graphical-GAN**)\n",
    "\n",
    "Z. Wang, et al., Face Aging with Identity-Preserved Conditional Generative Adversarial Networks, CVPR 2018. (**IPCGAN**)\n",
    "\n",
    "K. Hartmann, et al., EEG-GAN: Generative adversarial networks for electroencephalograhic (EEG) brain signals, 2018. (**EEG-GAN**)\n",
    "\n",
    "A. Gupta, et al., Social GAN: Socially Acceptable Trajectories with Generative Adversarial Networks, CVPR 2018. (**SGAN**)\n",
    "\n",
    "H. Zhang, et al., Self-Attention Generative Adversarial Networks, ICML 2019. (**SAGAN**)\n",
    "\n",
    "T. Karras, et al., A Style-Based Generator Architecture for Generative Adversarial Networks, CVPR 2019. (**StyleGAN**)\n",
    "\n",
    "A. Brock, et al., Large Scale GAN Training for High Fidelity Natural Image Synthesis, ICLR 2019. (**BigGAN**)\n",
    "\n",
    "J. Donahue, et al., Large Scale Adversarial Representation Learning, 2019. (**BigBiGAN**)\n",
    "\n",
    "A. Clark, et al., Efficient Video Generation on Complex Datasets, 2019. (**DVD-GAN**)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
